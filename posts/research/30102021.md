---
title: Four Phases in Machine Learning Life Cycle
summary: Artificial Intelligence (AI) becomes popular nowadays due to its applications across various industries such as healthcare, finance, education and others. Furthermore, technology supporting the development of AI becomes more accessible to many people at any ages such that they can easily learn and build AI applications online. While there are many online resources that mainly focus on the mathematical or statistical part such as building robust AI models, improving the accuracy of such models, and so on, online resources that teach best-practice in building scalable and extensible architectures surrounding developed models are few, elusive or even complicated. This leads to the fact that people tend to refer to AI models when they discuss about building AI applications. However, a successful AI application do not contain only the AI model itself but also the large architecture surrounding it as well human factors in the process. In this blog post, I share fundamental concepts on how AI applications are built in real life and the machine learning life cycle that is used by many practitioners in the AI community.
date: 30 Oct 2021
category: research
tag: Machine Learning
keywords: research, machine learning, machine learning life cycle, planning in machine learning project, machine learning project, data collection in machine learning, train and evaluate machine learning model, deploy machine learning model, machine learning in production
cover: https://dsm01pap002files.storage.live.com/y4mrrO91uI_zA8Vr1TGxCo2FFqyRZBqz5Fril-HMMMAtDp-2PrLR_1oTP9Cj4RbK9Wl1GM6eYL0tofbrIHphUjRmN11aPfpE3TdZDxhnoOYCzoIIaodEuUlKIMXm8UFSDjNpUY6Jc50nuRaVtChVYR-fH7tZ5-Sgow4YkDEHOz_HxlJSWsKGA-mtaJJO1Bd4n0N?width=2042&height=1366&cropmode=none
time: 15
---

Artificial Intelligence (AI) becomes popular nowadays due to its applications across various industries such as healthcare, finance, education and others. Furthermore, technology supporting the development of AI becomes more accessible to many people at any ages such that they can easily learn and build AI applications online. While there are many online resources that mainly focus on the mathematical or statistical part such as building robust AI models, improving the accuracy of such models, and so on, online resources that teach best-practice in building scalable and extensible architectures surrounding developed models are few, elusive or even complicated. This leads to the fact that people tend to refer to AI models when they discuss about building AI applications. However, a successful AI application do not contain only the AI model itself but also the large architecture surrounding it as well human factors in the process. In this blog post, I share fundamental concepts on how AI applications are built in real life and the machine learning life cycle that is used by many practitioners in the AI community.

---

## 1. AI applications are not only about the model
Back in 2009 when Netflix announced [the 1-million USD Grand Prize](https://www.netflixprize.com/) for developed algorithms that supported to improve the accuracy for their movie recommendations. In 2012, the company announced that they did not use the $1M algorithms in their real-time recommendation system because the algorithms required lots of engineering effort and their plan had slightly changed by then [[1](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429)]. Not only does this story teach us the importance of engineering effort in building a successful AI application, but it also changes the standard way we think about AI applications that is AI applications mainly focus on statistical models. According to [[2](https://learning.oreilly.com/library/view/agile-ai/9781492074984/), [3](https://fall2019.fullstackdeeplearning.com/)], the process of building an AI application consist of 5 components as:

1. Building teams and cultivating culture
2. Planning and capture requirements
3. Data focus tasks
4. Model focus tasks
5. Production focus tasks

Each component is equally important in the process. While the first two components focus on the non-technical side of an AI project, the 3rd and 4th components mainly concentrate on the technical side. Interestingly, the 5th component is the mix of both non-technical side and technical side. In terms of the non-technical side, the process of designing the interface (UI/UX) is involved with the purposes of getting the user's feedback and understanding the user's behaviour. Regarding the technical side, AI models must be optimally deployed under the observable environment where unexpected predictions and unknown data structures, also known as data drift, can be controlled. 

## 2. Four phases in building an AI application

In this section, we further discover four phases in building an AI application such as planning, data, model and production. This consists of the description of each phase, specific tasks per phase and tools that boost the productivity for each phase. Note that building teams and cultivating culture is the separate component in the corporation level. However, with small-sized or medium-sized projects, we tend to recruit and train people along with the planning phase.

![Figure 1. Four phases in building an AI application](https://dsm01pap002files.storage.live.com/y4mFXy_X1ihrg4Xp4iqts9dQ7y3ksOgx28_V_EBSgClSLwxyNvfRvHAmdL2VeyBtWKreHvGrmu5MOkGdzh1TRFqw5Kg-Z9d_LdNhfxcsibo19onxgnOVdDgzqwZxIs975lJRs3bg4ZST-Sk-OeQleNguIq0aP-RXU_yXGYCirV2vF9MbMH__pkfCEn-vlhmi0rj?width=1340&height=664&cropmode=none)

### 2.1. Planning phase

This phase consists of two crucial activities such as documenting business scenarios and forming teams with multidisciplinary skills.

__Documenting business scenarios:__ This activity requires us to talk with our clients or stakeholders who are interested in the project in order to capture as much requirements as possible. By doing so, we try to identify the problem statement and reasons why AI can be applied to solve the problem. Subsequently, we need to break the problem down to many achievable milestones in order to sprint out the project. Note that achievable factor depends on the capacity of the team, existing techniques and tools, and the support of third parties if necessary. The result of this activity consists of the clear problem statement, a list of requirements such as non-functional requirements and functional requirements, and sprints with a proper time frame.

__Forming teams with multidisciplinary skills:__ This activity is more about identifying the right people who can contribute significantly to the project or different sprints in the project. These people can be categorised into two groups such as a non-technical group and a technical group. Normally, subject matter experts (i.e., doctors, psychologists, biologists, or others), designers and business analysts are listed under the non-technical group. On the other hand, data scientists, software engineers, data engineers, AI researchers, and other technical roles are listed under the technical group. Ideally, each corporation has an individual or a group of individuals who is/are responsible for each role in a specific group. However, in many small-sized or medium-sized projects, especially the beginning period of many start-ups, the notion of role-specific or task-specific individual is luxurious or even unrealistic. Instead of that, one person in a team tends to be in charge of many roles such as designer, software engineer and data scientist. The role-specific individual or team can potentially ensure the quality for individual part in the project, but it may require the large budget and high demand in team management. Meanwhile, the multi-roles ones can minimise the budget of the project and have low demand in team management, but the quality of the project's outcome or the completion time for each sprint in the project may be affected negatively. Therefore, the project expense, delivery time and team management must be considered when forming teams for building an AI application.

### 2.2. Data phase

Every AI application requires data for multiple purposes such as training models, evaluating models, understanding the realistic facet of the proposed problem statement, and others. Here, we have four crucial activities such as data collection, data versioning, data pre-processing and data analytics.

__Data collection:__ We identify data sources that are relevant to the defined problem statement. They can come from existing datasets from various providers (i.e., [Kaggle](https://www.kaggle.com/), [Papers with Code](https://paperswithcode.com/datasets), [Hugging Face](https://huggingface.co/datasets), etc.), surveys, interviews, and others. Then, we need to classify the collected data into a specific type (i.e., structured data, unstructed data, or semi-structured data). Building good data collection in either the qualitative way or the quantitative way not only supports us to perform qualitative analytical tasks but also saves our resources and effort for the long run in building the entire AI application.

__Data versioning:__ After collecting data, we need to store them in either the file system or the dedicated database with an appropriate version. Since data will be quickly changed and evolved over the time, versioning the data collection supports us in many various facets such as analysing the difference between multiple versions, understanding the trend of the data, observing the relationship between the change of data collection and the performance of AI models, and others.

__Data pre-processing:__ To choose a right data pre-processing technique, we need to identify a type of the data that we intend to analyse. For example, the technique for pre-processing text data differs from that for pre-processing numeric data. Then, we start cleaning and transforming the data (e.g., filling missing values, type conversion, vectorisation, etc.) into the desired one that supports our analysis as well as model-related tasks.

__Data analytics:__ Once we have all desired data in place, we start performing the analysis on those in order to further understand the relationship between data entries, the trend of the data and outliers (i.e., strange data entries comparing the entire data collection), and other insights. Afterwards, we choose important features in the data used for training and evaluating ML/AI models.

### 2.3. Model phase

Once the data is available, we start building machine learning or deep learning models to tackle the proposed problem. Here, we have four crucial activities such as selecting proper models, training selected models, evaluating trained models and controlling the version for each train-evaluate trial.

__Model selection:__ To select proper ML/DL models, we need to fully understand the behaviour of the problem that we are trying to solve as well as the technical and mathematical aspects of a wide range of models. For example, KMeans algorithm is used for grouping data and recommending the group that a new data point belongs to. As another example, Linear Regression algorithm is used to predict a new data point based on the fitted line that infers the trend of all data points in a particular data collection. Here, we also need to understand the assumptions of each model to avoid overfitting (i.e., the model memorises the majority of the training data collection instead of learning) or underfitting (i.e., the model generates high error rate in both the training and testing data).

__Model training:__ To train a model, we first need to prepare the data for it. In practice, instead of using the entire data collection for training, we tend to split the collection in a certain proportion where the large proportion of the data is used for training and the rest is used for evaluation. Then, we need to understand hyperparameters (i.e., a model's configuration) and try multiple sets of them to find out the best set of hyperparameters. Note that different data collection used for the same model might generate the different sets of hyperparameters with the good result. Since the data keeps changing over the time, training model is the iterative procedure in order to be more adaptive with different scenarios.

__Model evaluation:__ The small proportion of the data split from the training stage is used in this procedure for evaluating a model trained with different sets of hyperparameters. Furthermore, this procedure aims to identify the best set of hyperparameters and the balance in the train-test data collection. Here, we firstly apply cross-validation and grid search in small chunks of the training data in order to find the best set of hyperparameters and the variation in the model performance. Secondly, given the best set of hyperparameters, we use it to re-train the model and use the trained model to generate score or prediction for the testing data. In addition, evaluation metrics such as accuracy, precision, recall, F1-score, and others are used to evaluate the performance of the model on the testing data. 

__Model versioning:__ Similar to versioning data collection, keeping track trained models with different sets of hyperparameters as well as different data collection helps us further understand the behaviour of the models. Here, we need to clearly document the experiment and its results for future reference. A normal template that we use for documentation a version of a model is below:

```
# Experiment date

# Data collection
 - version 
 - link

# Methodologies
- How was a model trained?
- How was a model evaluated?

# Results
- What is the best set of hyperparameters?
- What is the performance of the model?

# Discussion and Future Work
- What is the lesson learned from the experiment?
- What will we need to do to improve the model in the upcoming time?
```

### 2.4. Production phase

After the R&D stage, we start building the user interface and deploying the best ML/DL model for use. Here, there are three crucial activities such as deployment, model monitoring and gathering user feedback. 

__Deployment:__ This consists of both the user interface and the trained ML/DL model. However, in this post, we focus on the model facet. After finding the best model, we identify computing resources for hosting the model on the production. Here, we need to consider many components such as operating system, CPU, GPU, storage, a number of threads, and so forth. Scaling up & out need to be considered if we are about to deploy the model into the product having lots of users. Furthermore, we need to design and operate a convenient and automatic flow so that the deployment will be automatically triggered once the model has been updated.

__Model monitoring:__ Once the model is up and running on the production, we start monitoring how it behaves to user-generated data via the log system. This helps us control unpredictive results generated by the model and understand data generated by the user for the model. These pieces of information will be recorded for the sake of R&D. In this procedure, we are also able to observe the data drift issue that is unexpected user-generated data resulting in the poor performance of the model.

__Gathering user feedback:__ This activity is on-the-fly evaluation where we ask the user to rate the quality of recommendation generated by the model. These pieces of information will be recorded with the user's permission to improve the performance of the model. Feedback can be used in various ways depending on a particular recommendation task. For example, feedback for a prediction task with a regression model on the production can be used for the continuous offline experiment. As another example, feedback for a recommendation task with a reinforcement learning system can be used on-the-fly to continuously improve the model.

### 2.5. Tools for each phase

__Planning phase:__ 
* Documentation and project management: [Notion](https://www.notion.so/), [Trello](https://trello.com/), [Jira](https://www.atlassian.com/software/jira), [Coda](https://coda.io/welcome).
* Finding teams: [LinkedIn](https://www.linkedin.com/), [Kaggle](https://www.kaggle.com/), [Reddit](https://www.reddit.com/), [DEV](https://dev.to/), or other social media or recruitment platforms.

__Data, Model and Production phases:__

![Figure 2. The Map of Tools in [3](https://fall2019.fullstackdeeplearning.com/)](https://dsm01pap002files.storage.live.com/y4mLn3LlrABvqOY3185JYvECiSG05uwHrf3lsenItvxOZ018PswISzr8ooDwTS3FcMCmO1471MqbKsKVBa9XclH8L4kTSapooeXGgD8cQmE3zrcW3mQugDBn78bXLl-tD7uxpZGZUhkC423dVowGXUCHCKVi02HWR0ImUFArpGUh2Q2YhL6dg3kgk-_VzhG5YgP?width=3250&height=1800&cropmode=none)

![Figure 3. The Stack of Tools in [2](https://learning.oreilly.com/library/view/agile-ai/9781492074984/)](https://dsm01pap002files.storage.live.com/y4mR0FBNoYnN5vF2SWv4HAI7Qbbf0rb5LpJQmdliOqJLh6_tZYRDc0olxY43OfN4xPPAd_-Zu1KNFdGQ1rhiPd3cWl52j23Gzjd_Prks0cTLYQkzRZ6STUoNSopDsQ7YOW1HPpKf5VHKGcXyWClOcK_v6oNbU1e6RAVKUFmSIHpp98ZW8tacRtHE1medXcsdxw_?width=944&height=589&cropmode=none)

## 3. Machine learning life cycle

![Figure 4. Machine learning life cycle](https://dsm01pap002files.storage.live.com/y4merrgFjGyrV2bR-QPnxk_H6Wvqq7t2RCA375-1vV2dnBhzXX3kwsE68XtXsWUGj2YSlssDLR8CVZCp4TbUDsvseAzBNA3eqfKOPraEmTInXV4dHR057b0UeHR1e60Jc7XO1ADf21ESSjxdTGbPo9o4sEaE-fYhuTQlivkV2IE1qAC60ELdCaX16P3oaN_rvu0?width=1444&height=761&cropmode=none)

So far, we have discussed four phases in building an AI application in a separate order. This section covers the connection between those phases that creates the machine learning life cycle in many real-world applications (see also Figure 4). The flow in Figure 4 is described below:

__Project planning:__ After identifying the problem statement, we start breaking it down to many project scopes. Then, we start establishing a plan for completing each project scope.

__(1)__: After identifying tasks for the project scope, we start finding data collection or labelling data that are relevant to the scope. __(1.1)__: However, at this stage, we might start to realise that there is no existing data collection, or it is difficult and time-consuming to find or produce one. Hence, we are back to the planning stage to adjust the scope of the project.

__(2)__: If we have successfully collected or labelled data supporting the project scope, we start digging into the model phase in order to explore ML/DL models. __(2.1)__: However, at this stage, we might start to realise that the prepared data is biased, dirty or not suitable for any existing models that supports the project scope. Hence, we need to go back to the data phase for adjustment. __(2.2):__ On the other hand, if the issue is not coming from our prepared data, we might start to realise that there are no such existing models that supports the project scope well, or it is time-consuming and cost unexpected R&D resources to produce one. Therefore, we need to go back to the planning phase to review and adjust the scope of the project.

__(3)__: If we have successfully trained the best model supporting the project scope, we are ready to deploy and monitor it on the production system where unexpected scenarios might occur. __(3.1.):__ However, at this stage, we start to realise that the model is too heavy for the current system capacity to deploy or negatively affects the experience of users. Hence, we need to go back to the data phase to further optimise the model. __(3.2.):__ On the other hand, we might start to realise that our prepared data for the trained model does not reflect the real facet of the user-generated data from the production system. Hence, we need to go back to the data phase for further investigation and adjustment.

__(4)__: If there is no issues or minor issues generated by the model that we can accept on the production system, we will move on the next project scope and repeat the entire procedure from __(1)__ to __(4)__.

## References
1. Netflix Technology Blog, 2012, _Netflix Recommendations Beyong the 5 starts_, [Blog post](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429).
2. Carlo Appugliese, Paco Nathan & William S. Roberts, 2020, _Agile AI_, [OReilly eBook](https://learning.oreilly.com/library/view/agile-ai/9781492074984/).
3. Josh Tobin, Sergey Karayev, Stephanie Sher, James Le & Pieter Abbeel, 2019, _Full Stack Deep Learning_, [Website](https://fall2019.fullstackdeeplearning.com/)
